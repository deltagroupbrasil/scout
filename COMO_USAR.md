# üìñ Como Usar o LeapScout

Guia completo para o usu√°rio final usar o sistema de scraping de vagas.

---

## üéØ 3 Formas de Buscar Vagas

### **1. ‚è∞ Scraping Autom√°tico (Recomendado)**

O sistema roda **automaticamente todos os dias √†s 6h da manh√£** buscando novas vagas.

**O que acontece:**
- Sistema busca vagas no LinkedIn, Gupy e Catho
- Enriquece dados da empresa (CNPJ, faturamento, funcion√°rios)
- Gera insights com IA (contatos sugeridos, gatilhos de abordagem)
- Calcula score de prioridade (0-100)
- Salva tudo no dashboard

**Voc√™ n√£o precisa fazer nada!** üéâ

---

### **2. üñ±Ô∏è Scraping Manual via Dashboard**

Acesse o dashboard e use o bot√£o de scraping manual:

1. Abra **http://localhost:3000/dashboard**
2. Clique em **"Buscar Novas Vagas"** (bot√£o azul no header, ao lado de "Exportar CSV")
3. Aguarde o processamento (pode levar 3-5 minutos)
4. Voc√™ ver√° notifica√ß√µes (toasts) informando:
   - "Buscando vagas..." (durante o processo)
   - "Busca conclu√≠da! X novas vagas encontradas em Y minutos" (sucesso)
   - Ou mensagem de erro se algo falhar
5. Vagas aparecer√£o automaticamente na lista ap√≥s conclus√£o

**Importante**: O bot√£o ficar√° desabilitado durante o processamento para evitar m√∫ltiplas execu√ß√µes simult√¢neas.

---

### **3. üîß Scraping Manual via API**

Para desenvolvedores ou automa√ß√µes avan√ßadas:

#### **Via Browser (teste r√°pido)**
```bash
# Abrir no navegador:
http://localhost:3000/api/cron/scrape-leads
```

#### **Via cURL**
```bash
curl -X POST http://localhost:3000/api/cron/scrape-leads
```

#### **Via Postman/Insomnia**
- **Method**: POST
- **URL**: http://localhost:3000/api/cron/scrape-leads
- **Headers**: Nenhum (em dev)

**Resposta esperada:**
```json
{
  "success": true,
  "leadsCreated": 12,
  "duration": 45,
  "message": "Scraping conclu√≠do com sucesso. 12 leads criados."
}
```

---

## üìä Visualizar Resultados

### **Dashboard Principal**
http://localhost:3000/dashboard

**O que voc√™ v√™:**
- ‚úÖ Lista de todas as vagas encontradas
- ‚úÖ Score de prioridade (Muito Alta, Alta, M√©dia, Baixa)
- ‚úÖ Dados da empresa (CNPJ, faturamento, funcion√°rios)
- ‚úÖ Filtros por status, data, prioridade
- ‚úÖ Busca por palavra-chave

### **Detalhes do Lead**
Clique em qualquer vaga para ver:
- üìã Descri√ß√£o completa da vaga
- üè¢ Informa√ß√µes detalhadas da empresa
- üë• Contatos sugeridos pela IA (nome, cargo, email, LinkedIn)
- üéØ Gatilhos de abordagem (gerados pela IA)
- üìù Notas e hist√≥rico de intera√ß√µes
- üìä Score de prioridade com breakdown

---

## ‚öôÔ∏è Configura√ß√µes

### **Alterar Query de Busca**

As vagas buscadas s√£o definidas no c√≥digo. Para alterar:

**Arquivo**: `app/api/cron/scrape-leads/route.ts`
```typescript
// Linha 53 - Altere a query aqui
const query = 'Controller OR CFO OR "Gerente Controladoria" S√£o Paulo'
```

**Exemplos de queries:**
```
"Controller S√£o Paulo"
"CFO OR Controladoria Rio de Janeiro"
"Gerente Financeiro BPO Brasil"
"Controller AND (Controladoria OR CFO) S√£o Paulo"
```

### **Alterar Frequ√™ncia do Cron**

**Arquivo**: `vercel.json`
```json
{
  "crons": [{
    "path": "/api/cron/scrape-leads",
    "schedule": "0 6 * * *"  // ‚Üê Altere aqui (formato cron)
  }]
}
```

**Exemplos de schedules:**
- `0 6 * * *` - Todos os dias √†s 6h
- `0 */4 * * *` - A cada 4 horas
- `0 9 * * 1` - Todas segundas-feiras √†s 9h
- `0 8,18 * * *` - Todos os dias √†s 8h e 18h

> **Aten√ß√£o**: O cron s√≥ funciona em produ√ß√£o (Vercel). Em desenvolvimento, use chamada manual.

---

## üîç Fontes de Vagas

O sistema busca vagas em **3 fontes simultaneamente**:

| Fonte | Status | Observa√ß√£o |
|-------|--------|------------|
| **LinkedIn** | ‚úÖ Funcional | Usa Puppeteer da Bright Data |
| **Gupy** | ‚ö†Ô∏è Mock | Dados simulados (aguarda teste real) |
| **Catho** | ‚ö†Ô∏è Mock | Dados simulados (aguarda teste real) |

**Para ativar Gupy e Catho reais:**
1. Ajustar seletores CSS em `lib/services/web-unlocker.ts`
2. Testar com `npx tsx scripts/test-web-unlocker.ts`
3. Deploy autom√°tico ap√≥s teste

---

## üìà Monitoramento

### **Ver Logs de Scraping**

**Via Prisma Studio:**
```bash
npx prisma studio
```
1. Abrir **ScrapeLog** na sidebar
2. Ver hist√≥rico de execu√ß√µes (status, dura√ß√£o, erros)

**Via Dashboard** (futuro):
- Se√ß√£o "Hist√≥rico de Scraping" com estat√≠sticas

---

## ‚ùì Perguntas Frequentes

### **1. Quanto tempo leva para buscar vagas?**
- LinkedIn: 30-60 segundos
- Gupy/Catho: 15-30 segundos cada
- **Total**: ~1-2 minutos para todas as fontes

### **2. Quantas vagas s√£o encontradas por dia?**
Depende da query, mas em m√©dia:
- LinkedIn: 10-50 vagas
- Gupy: 5-20 vagas
- Catho: 5-20 vagas
- **Total**: 20-90 vagas/dia

### **3. O sistema busca vagas duplicadas?**
N√£o! O sistema verifica se a vaga j√° existe pela URL antes de criar.

### **4. Como sei se o scraping est√° funcionando?**
1. Acesse http://localhost:3000/dashboard
2. Verifique a data da √∫ltima vaga criada
3. Ou acesse Prisma Studio e veja a tabela `ScrapeLog`

### **5. Erro "Rate limit exceeded"?**
Isso acontece quando voc√™ faz muitas requisi√ß√µes em pouco tempo.
**Solu√ß√£o**: Aguarde 1 minuto e tente novamente.

### **6. Posso buscar vagas de outras √°reas?**
Sim! Basta alterar a query de busca (ver se√ß√£o "Configura√ß√µes")

---

## üöÄ Pr√≥ximas Features

- [x] Bot√£o "Buscar Vagas" no dashboard
- [ ] Configura√ß√£o de query via interface
- [ ] Notifica√ß√µes de novas vagas de alta prioridade
- [ ] Relat√≥rios semanais por email
- [ ] Dashboard de estat√≠sticas de scraping

---

**√öltima atualiza√ß√£o**: 12/11/2025
**Desenvolvido por**: Leap Solutions
